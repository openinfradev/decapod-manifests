# Source: lma-addons/templates/prometheus-rule/basic-linux.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  annotations:
    prometheus-operator-validated: "true"
  name: basic-linux
  namespace:  
spec:
#basic_linux:
  groups:
  - name: basic_linux.rules
    rules:
    - alert: node_filesystem_full_80percent
      expr: sort(node_filesystem_free_bytes{fstype =~ "xfs|ext[34]"} < node_filesystem_size_bytes{fstype =~ "xfs|ext[34]"} * 0.2) / 1024 ^ 3
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{ $labels.instance }} device {{ $labels.device }} on {{ $labels.mountpoint }} got less than 10% space left on its filesystem. ({{ $labels.taco_cluster  }})'
        summary: '{{ $labels.instance }}: Filesystem is running out of space soon. ({{ $labels.taco_cluster }})'
    - alert: node_filesystem_full_in_4h
      expr: predict_linear(node_filesystem_free_bytes{fstype =~ "xfs|ext[34]"}[1h], 4 * 3600) <= 0
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{ $labels.instance }} device {{ $labels.device }} on {{ $labels.mountpoint }} is running out of space of in approx. 4 hours ({{ $labels.taco_cluster }})'
        summary: '{{ $labels.instance }}: Filesystem is running out of space in 4 hours. ({{ $labels.taco_cluster }})'
    - alert: node_filedescriptors_full_in_3h
      expr: predict_linear(node_filefd_allocated[1h], 3 * 3600) >= node_filefd_maximum
      for: 20m
      labels:
        severity: warning
      annotations:
        message: '{{ $labels.instance }} is running out of available file descriptors in approx. 3 hours ({{ $labels.taco_cluster }})'
        summary: '{{ $labels.instance }} is running out of available file descriptors in 3 hours. ({{ $labels.taco_cluster }})'
    - alert: node_load1_90percent
      expr: node_load1 / ON(instance, taco_cluster) count(node_cpu_seconds_total{mode="system"}) BY (instance,taco_cluster) >= 0.9
      for: 1h
      labels:
        severity: page
      annotations:
        message: '{{ $labels.instance }} is running with > 90% total load for at least 1h. ({{ $labels.taco_cluster }})'
        summary: '{{ $labels.instance }}: Running on high load. ({{ $labels.taco_cluster }})'
    - alert: node_cpu_util_90percent
      expr: instance:node_cpu:ratio >= 0.9
      for: 1h
      labels:
        severity: page
      annotations:
        message: '{{ $labels.instance }} has total CPU utilization over 90% for at least 1h. ({{ $labels.taco_cluster }})'
        summary: '{{ $labels.instance }}: High CPU utilization. ({{ $labels.taco_cluster }})'
    - alert: node_ram_using_90percent
      expr: node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes < node_memory_MemTotal_bytes * 0.1
      for: 30m
      labels:
        severity: page
      annotations:
        message: '{{ $labels.instance }} is using at least 90% of its RAM for at least 30 minutes now. ({{ $labels.taco_cluster }})'
        summary: '{{ $labels.instance }}: Using lots of RAM. ({{ $labels.taco_cluster }})'
    # - alert: node_swap_using_80percent
    #   expr: node_memory_SwapTotal_bytes - (node_memory_SwapFree_bytes + node_memory_SwapCached_bytes) > node_memory_SwapTotal_bytes * 0.8
    #   for: 10m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{ $labels.instance}}
    #       is using 80% of its swap space for at least 10 minutes now.'
    #     summary: '{{ $labels.instance}}:
    #       Running out of swap soon.'
    # - alert: node_high_cpu_load
    #   expr: node_load1 / ON(instance, taco_cluster) count(node_cpu_seconds_total{mode="system"}) BY (instance,taco_cluster) >= 0.8
    #   for: 1m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{ $labels.instance}} is running with load15 > 1 for at least 5 minutes: {{$value}}`}} ({{ $labels.taco_cluster }})'
    #     summary: '{{ $labels.instance}}: Running on high load: {{ $value}} ({{ $labels.taco_cluster }})'
    - alert: node_high_memory_load
      expr: (sum(node_memory_MemTotal_bytes)by(instance,taco_cluster) - sum(node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes)by(instance,taco_cluster)) / sum(node_memory_MemTotal_bytes)by(instance,taco_cluster) * 100 > 85
      for: 1m
      labels:
        severity: warning
      annotations:
        message: Host memory usage is {{ humanize $value }}%. Reported by instance {{ $labels.instance }} of job {{ $labels.job }}. ({{ $labels.taco_cluster }})
        summary: Server memory is almost full ({{ $labels.taco_cluster }})
    - alert: node_high_storage_load
      expr: (node_filesystem_size_bytes{mountpoint="/"} - node_filesystem_free_bytes{mountpoint="/"}) / node_filesystem_size_bytes{mountpoint="/"} * 100 > 85
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host storage usage is {{ humanize $value }}%. Reported by instance {{ $labels.instance }} of job {{ $labels.job }}. ({{ $labels.taco_cluster }})
        summary: Server storage is almost full ({{ $labels.taco_cluster }})
    # - alert: node_high_swap
    #   expr: (node_memory_SwapTotal_bytes - node_memory_SwapFree_bytes) < (node_memory_SwapTotal_bytes * 0.4)
    #   for: 1m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: Host system has a high swap usage of {{ humanize $value }}. Reported by instance {{ $labels.instance }} of job {{ $labels.job }}.
    #     summary: Server has a high swap usage
    - alert: node_high_network_drop_rcv
      expr: increase(node_network_receive_drop_total{device!="lo"}[2m]) > 100
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high drop in network reception ({{ humanize $value }}). Reported by instance {{ $labels.instance }} of job {{ $labels.job }} ({{ $labels.taco_cluster }})
        summary: Server has a high receive drop ({{ $labels.taco_cluster }})
    - alert: node_high_network_drop_send
      expr: increase(node_network_transmit_drop_total{device!="lo"}[2m]) > 100
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high drop in network transmission ({{ humanize $value }}). Reported by instance {{ $labels.instance }} of job {{ $labels.job }} ({{ $labels.taco_cluster }})
        summary: Server has a high transmit drop ({{ $labels.taco_cluster }})
    - alert: node_high_network_errs_rcv
      expr: node_network_receive_errs_total{device!="lo"} > 3000
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high error rate in network reception ({{ humanize $value }}). Reported by instance {{ $labels.instance }} of job {{ $labels.job }} ({{ $labels.taco_cluster }})
        summary: Server has unusual high reception errors ({{ $labels.taco_cluster }})
    - alert: node_high_network_errs_send
      expr: node_network_transmit_errs_total{device!="lo"} > 3000
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high error rate in network transmission ({{ humanize $value }}). Reported by instance {{ $labels.instance }} of job {{ $labels.job }} ({{ $labels.taco_cluster }})
        summary: Server has unusual high transmission errors ({{ $labels.taco_cluster }})
    - alert: node_network_conntrack_usage_80percent
      expr: sort(node_nf_conntrack_entries{job="node-exporter"} > node_nf_conntrack_entries_limit{job="node-exporter"}  * 0.8)
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{ $labels.instance }} has network conntrack entries of {{ $value }} which is more than 80% of maximum limit ({{ $labels.taco_cluster }})'
        summary: '{{ $labels.instance }}:
          available network conntrack entries are low. ({{ $labels.taco_cluster }})'
    - alert: node_entropy_available_low
      expr: node_entropy_available_bits < 300
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{ $labels.instance }} has available entropy bits of {{ $value }} which is less than required of 300 ({{ $labels.taco_cluster }})'
        summary: '{{ $labels.instance }}: is low on entropy bits. ({{ $labels.taco_cluster }})'
    - alert: node_hwmon_high_cpu_temp
      expr: node_hwmon_temp_crit_celsius*0.9 - node_hwmon_temp_celsius < 0 OR node_hwmon_temp_max_celsius*0.95 - node_hwmon_temp_celsius < 0
      for: 5m
      labels:
        severity: critical
      annotations:
        message: '{{ $labels.instance }} reports hwmon sensor {{ $labels.sensor }}/{{ $labels.chip }} temperature value is nearly critical: {{ $value }} ({{ $labels.taco_cluster }})'
        summary: '{{ $labels.instance }}: Sensor {{ $labels.sensor }}/{{$labels.chip }} temp is high: {{ $value }} ({{ $labels.taco_cluster }})'
    - alert: node_vmstat_paging_rate_high
      expr: irate(node_vmstat_pgpgin[5m]) > 80
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{ $labels.instance }} has a memory paging rate of change higher than 80%: {{ $value }} ({{ $labels.taco_cluster }})'
        summary: '{{ $labels.instance }}: memory paging rate is high: {{ $value }} ({{ $labels.taco_cluster }})'
    # xfs사용하는 곳 없음
    # - alert: node_xfs_block_allocation_high
    #   expr: 100*(node_xfs_extent_allocation_blocks_allocated_total{job="node-exporter", instance=~"172.17.0.1.*"} / (node_xfs_extent_allocation_blocks_freed_total{job="node-exporter", instance=~"172.17.0.1.*"} + node_xfs_extent_allocation_blocks_allocated_total{job="node-exporter", instance=~"172.17.0.1.*"})) > 80
    #   for: 5m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{ $labels.instance}}
    #       has xfs allocation blocks higher than 80%: {{$value}}'
    #     summary: '{{ $labels.instance}}:
    #       xfs block allocation high: {{ $value}}'
    - alert: node_network_bond_slaves_down
      expr: node_bonding_slaves - node_bonding_slaves_active > 0
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{ $labels.master }} is missing {{ $value }} slave interface(s). ({{ $labels.taco_cluster }})'
        summary: 'Instance {{ $labels.instance }}: {{ $labels.master }} missing {{ $value }} slave interface(s) ({{ $labels.taco_cluster }})'
    # - alert: node_numa_memory_used
    #   expr: 100*node_memory_numa_MemUsed_bytes / node_memory_numa_MemTotal_bytes > 80
    #   for: 5m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{ $labels.instance}}
    #       has more than 80% NUMA memory usage: {{ $value}} ({{ $labels.taco_cluster }})'
    #     summary: '{{ $labels.instance}}:
    #       has high NUMA memory usage: {{ $value}} ({{ $labels.taco_cluster }})'
    - alert: node_ntp_clock_skew_high
      expr: abs(node_ntp_drift_seconds) > 2
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{ $labels.instance }} has time difference of more than 2 seconds compared to NTP server: {{ $value }} ({{ $labels.taco_cluster }})'
        summary: '{{ $labels.instance }}: time is skewed by : {{ $value }} seconds ({{ $labels.taco_cluster }})'
    - alert: node_disk_read_latency
      expr: (rate(node_disk_read_time_seconds_total[5m]) / rate(node_disk_reads_completed_total[5m])) > 40
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{ $labels.device }} has a high read latency of {{ $value }} ({{ $labels.taco_cluster }})'
        summary: High read latency observed for device {{ $labels.device }} ({{ $labels.taco_cluster }})
    - alert: node_disk_write_latency
      expr: (rate(node_disk_write_time_seconds_total{device!~"rbd.*"}[5m]) / rate(node_disk_writes_completed_total[5m])) > 40
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{ $labels.device }} has a high write latency of {{ $value }} ({{ $labels.taco_cluster }})'
        summary: High write latency observed for device {{ $labels.device }} ({{ $labels.taco_cluster }})
